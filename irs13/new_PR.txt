package edu.asu.irs13;

import static java.lang.Math.abs;

import java.io.FileNotFoundException;
import java.io.IOException;
import java.io.PrintWriter;

import org.apache.lucene.index.IndexReader;

public class PrioritizedPageRank {

	
	static private double reset; // will store the reset matrix value. Currently it is 1/corpus size.
	static private double prob = 0.8; // the probability with which the user will not jump to some other link.
	static private double sink; // will store the value for sink nodes. Currently it is 1/corpus size.
	static private int iterations = 0; // to keep count of the iterations it takes to converge.
	
	public static double[] computePageRank(IndexReader r, LinkAnalysis l) throws FileNotFoundException, IOException
	{
		long time = System.currentTimeMillis(); // for time analysis.
		int n = r.maxDoc();
		sink = 1.0/(double)n; // sink = 1/(corpus size)
		reset = 1.0/(double)n; // reset = 1/(corpus size)
		double[][] pageRank = new double[2][n]; // pageRank vector created and initialized
		for(int i = 0; i < n; i++)
		{
			pageRank[0][i] = 1.0/(double)n;
			pageRank[1][i] = 1.0;
		}
		double[][] vec = new double[2][n]; // vector created to store the previous pageRank vector
		double max = 0.0; // to store the max pageRank value of a doc. Used to normalize the vector.
		double min = 0.0;
		do
		{
			iterations++; // number of iterations incremented
			long time2 = System.currentTimeMillis(); // to analyze time taken for each iteration.
			vec = pageRank;
			min = 1.0;
			pageRank = new double[2][n]; // pageRank given new memory basically to overwrite old values.
			double temp_max = 0.0; // max value of the current value. TODO: can be removed.
			for(int k = 0; k < n; k++) // for each row of matrix M*
			{
				if(vec[1][k] == iterations)
				{	
					int[] cits = l.getCitations(k); // will give us cells which will be non-zero in this row.
					boolean[] my_cits = new boolean[n]; // boolean array to store these cells.
					for(int c = 0; c < cits.length; c++)
						my_cits[cits[c]] = true;
					for(int i = 0; i < n; i++) // for each column of matrix M*
					{
						double val = 0.0;
						int[] link = l.getLinks(i);
						if(link.length > 0) // not a sink node.
						{
							if(my_cits[i]) // if true then non-zero value else zero.
								val = 1.0/(double)link.length;
						}
						else // sink node.
							val = sink;
						pageRank[0][k] += (val*prob + reset*(1-prob))*vec[0][i]; // the summation will compute one cell of pageRank vector.
					}
					pageRank[1][k] = iterations;
					if(temp_max < pageRank[0][k]) // to get the max value of the current pageRank vector.
						temp_max = pageRank[0][k];
					if(min > pageRank[0][k])
						min = pageRank[0][k];
				}
				else
				{
					pageRank[0][k] = vec[0][k];
					pageRank[1][k] = vec[1][k];
				}
			}
			max = temp_max;
			time2 = System.currentTimeMillis() - time2; // time taken for each iteration.
			System.out.println("Completed iteration " +iterations+ " in " +time2+ " milliseconds");
		}while(!checkEigen(vec, pageRank)); // check if the vector converge.
		
		PrintWriter rank_writer = new PrintWriter("Prank.txt", "UTF-8");
		rank_writer.println("RANKS");
		for(int i = 0; i < n; i++)
		{
			//pageRank[i][0] = (pageRank[i][0] - min)/(max - min); // scale between 0 and 1
			//pageRank[i] = 1/(1.0 + log(max/pageRank[i])); // normalize the vector.
			rank_writer.println("DocID: "+ i+ " :" +pageRank[0][i] + ": iterated: " +pageRank[1][i]);
		}
		rank_writer.close();
		/*int[] count = new int[n*10+1];
		for(int i = 0; i < n; i++)
		{
			count[getIndex(pageRank[i]*10.0)]++;
		}*/
		time = (System.currentTimeMillis() - time)/1000; // total time taken to compute pageRank.
		System.out.println("Page Rank computed in: " +time+ " seconds");
		return pageRank[0]; // pageRank computed. yuppiee!!
	}
	
	static boolean checkEigen(double[][] a, double[][]b)
	{
		int i = 0;
		boolean flag = true;
		while(i < a.length)
		{
			if(abs(a[0][i] - b[0][i]) > 0.0001)
			{
				b[1][i] = iterations +1;
				flag = false;
			}
			i++;
		}
		return flag;
	}
	
}